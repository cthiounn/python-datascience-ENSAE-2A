{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b01e4-4a70-46ef-8904-4449c3b95a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7417eb0-1fbf-40b9-8124-147eeb71682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r donnees_2018_hab\n",
    "%store -r donnees_2018\n",
    "donnees_2018_hab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c4801d-1b86-4f17-a42e-7ae430f92462",
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees_2018_hab=donnees_2018_hab.drop(columns=['REG', 'Libellé','Crim_Del_PN_GN','Crim_Del_GN_hab','Crim_Del_PN_hab'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1577de-700d-4558-acc8-6d0016ffb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# donnees_2018_hab=donnees_2018_hab[(donnees_2018_hab.index<'91') & (donnees_2018_hab.index!='75') & (donnees_2018_hab.index!='2A') & (donnees_2018_hab.index!='2B')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05fcdbe-ca2b-477e-bee2-9a3dad672bbe",
   "metadata": {},
   "source": [
    "# 1 - Approche économétrique\n",
    "\n",
    "Dans une première approché économétrique, nous essayons de prédire le nombre de crimes à partir du nombre de boucherie et des autres variables de contrôles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e928df-2a5d-4e34-9b6b-09bb23efd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://towardsdatascience.com/simulating-replicating-r-regression-plot-in-python-using-sklearn-4ee48a15b67\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "\n",
    "df_train, df_test = train_test_split(donnees_2018_hab, \n",
    "                                     train_size = 0.7, \n",
    "                                     test_size = 0.3\n",
    "                                    )\n",
    "\n",
    "X_train=df_train[['MED18', 'TP6018', 'D118', 'D918', 'RD18', 'T1_2018',\n",
    "       'Nb_PN_GN_dep_100k_hab', 'Nb_Boucherie_dep_hab']]\n",
    "y_train=df_train[['Crim_Del_PN_GN_hab']]\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "X_test=df_test[['MED18', 'TP6018', 'D118', 'D918', 'RD18', 'T1_2018',\n",
    "       'Nb_PN_GN_dep_100k_hab', 'Nb_Boucherie_dep_hab']]\n",
    "y_test=df_test[['Crim_Del_PN_GN_hab']]\n",
    "\n",
    "# # for predictions\n",
    "predictions = lm.predict(X_test)\n",
    "lm.coef_\n",
    "lm.intercept_\n",
    "scores = cross_val_score(lm, X_train, y_train, scoring='r2', cv=5)\n",
    "scores\n",
    "# R² can be negative with small datasets and cv fold https://stackoverflow.com/questions/23036866/scikit-learn-is-returning-coefficient-of-determination-r2-values-less-than-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb97ec-58bb-44ed-bde9-7f8039f3924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.residplot(predictions.reshape(-1),'Crim_Del_PN_GN_hab', data=df_test,lowess=True,\n",
    "                                  line_kws={'color': 'red', 'lw': 1, 'alpha': 1})\n",
    "plt.xlabel(\"Fitted values\")\n",
    "plt.title('Residual plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c17af4b-5e88-406e-a0f4-d86fd7ad663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = df_test[\"Crim_Del_PN_GN_hab\"] - predictions.reshape(-1)\n",
    "residuals\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4da845-c6be-4b5b-929a-b73c42a5ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_norm_residuals_abs_sqrt=np.sqrt(np.abs(residuals))\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.regplot(predictions.reshape(-1), model_norm_residuals_abs_sqrt,\n",
    "              scatter=True,\n",
    "              lowess=True,\n",
    "              line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "plt.ylabel(\"Standarized residuals\")\n",
    "plt.xlabel(\"Fitted value\")\n",
    "\n",
    "# Hétéroscédasticité\n",
    "# Woolridge's Introductory Econometrics suggest taking the natural log for : \n",
    "# * conditional distributions that are heteroskedastic or skewed;\n",
    "# * Population variables\n",
    "# * log(1+y) if 0 exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3cd5bc-a9b5-45ac-8923-629e0a08be48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
