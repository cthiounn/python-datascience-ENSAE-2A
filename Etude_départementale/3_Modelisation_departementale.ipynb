{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e840bdb0-2b8c-4045-b106-10a5313a4f4b",
   "metadata": {},
   "source": [
    "# Chapitre 3 - Modélisation statistique et économétrique des données départementales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e777dd-750b-4d87-a914-702bda7da744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètre(s) du notebook\n",
    "\n",
    "# VERBOSE=True\n",
    "VERBOSE=False\n",
    "\n",
    "OPTIONS=\"\"\n",
    "if not VERBOSE:\n",
    "    OPTIONS=\"--quiet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b01e4-4a70-46ef-8904-4449c3b95a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats\n",
    "from statsmodels.formula.api import ols\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import (Lasso,LassoCV)\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7417eb0-1fbf-40b9-8124-147eeb71682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r donnees_2018_hab\n",
    "%store -r donnees_2018\n",
    "%store -r X_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c4801d-1b86-4f17-a42e-7ae430f92462",
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees_2018_hab=donnees_2018_hab.drop(columns=['REG', 'Libellé','Crim_Del_PN_GN','Crim_Del_GN_hab','Crim_Del_PN_hab'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05fcdbe-ca2b-477e-bee2-9a3dad672bbe",
   "metadata": {},
   "source": [
    "# 1 - Approche économétrique\n",
    "\n",
    "Dans une première approché économétrique, nous essayons de prédire le nombre de crimes à partir uniquement du nombre de boucherie, puis en rajoutant des variables de contrôles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db661dd4-5de4-43ce-8969-64a8e2c0ce22",
   "metadata": {},
   "source": [
    "## 1-A Régression linéaire simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6151375-a33a-4a1a-a957-8d041806ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*100)\n",
    "print(\"\"*100)\n",
    "print(\"Une régression simple sur l'ensemble des données non transformées :\")\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8319b6e-fdae-4e44-a902-f301ba611518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://towardsdatascience.com/simulating-replicating-r-regression-plot-in-python-using-sklearn-4ee48a15b67\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "X=donnees_2018_hab[[ 'Nb_Boucherie_dep_hab']]\n",
    "Y=donnees_2018_hab[['Crim_Del_PN_GN_hab']]\n",
    "\n",
    "lm.fit(X, Y)\n",
    "\n",
    "\n",
    "# # for predictions\n",
    "predictions = lm.predict(X)\n",
    "\n",
    "beta_hat = [lm.intercept_.tolist()] + lm.coef_.tolist()\n",
    "print(\"coefficients : \",beta_hat)\n",
    "print(\"score :\", lm.score(X,Y))\n",
    "plt.scatter(X, Y)\n",
    "plt.xlabel(\"Nb_Boucherie_dep_hab\")\n",
    "plt.ylabel(\"Crim_Del_PN_GN_hab\")\n",
    "plt.title('Nb_Boucherie_dep_hab*Crim_Del_PN_GN_hab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507fd547-ac70-4be5-a2b6-721bfe530b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_with_statsmodels = ols(\" Crim_Del_PN_GN_hab ~  Nb_Boucherie_dep_hab\", data = donnees_2018_hab).fit()\n",
    "print(reg_with_statsmodels.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ebb8fa-325e-4bc8-b793-f8699454a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \"*100)\n",
    "print(\" ----- INTERPRETATION : le modèle est invalide par la F-statistique et la non significativité du coefficient associé à Nb_Boucherie_dep_hab   (R² quasi nul) \")\n",
    "print(\" ----- INTERPRETATION : le R² est quasi nul, suggérant la non-corrélation des deux variables, et ainsi un faible pouvoir prédictif \")\n",
    "print(\" ----- INTERPRETATION : on tente de rajouter des régresseurs supplémentaires pour gagner en prédictivité.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b479f4-627f-404f-b1fe-c4447cca1fed",
   "metadata": {},
   "source": [
    "## 1-B Régression linéaire multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f9c64-4886-4267-b159-0a46643f24c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*100)\n",
    "print(\" \"*100)\n",
    "print(\"Une régression multiple sur l'ensemble des données non transformées :\")\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e928df-2a5d-4e34-9b6b-09bb23efd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://towardsdatascience.com/simulating-replicating-r-regression-plot-in-python-using-sklearn-4ee48a15b67\n",
    "lm = LinearRegression()\n",
    "\n",
    "X=donnees_2018_hab[['MED18', 'TP6018', 'D118', 'D918', 'RD18', 'T1_2018',\n",
    "       'Nb_PN_GN_dep_100k_hab', 'Nb_Boucherie_dep_hab']]\n",
    "Y=donnees_2018_hab[['Crim_Del_PN_GN_hab']]\n",
    "\n",
    "lm.fit(X, Y)\n",
    "\n",
    "\n",
    "\n",
    "# # for predictions\n",
    "predictions = lm.predict(X)\n",
    "print(\"variables explicatives\",['MED18', 'TP6018', 'D118', 'D918', 'RD18', 'T1_2018',\n",
    "       'Nb_PN_GN_dep_100k_hab', 'Nb_Boucherie_dep_hab'])\n",
    "print(\"coefficients\",lm.coef_)\n",
    "print(\"constante\",lm.intercept_)\n",
    "\n",
    "print(\"R² :\",lm.score(X, Y))\n",
    "print(\" \"*100)\n",
    "print(\" ----- INTERPRETATION : nous obtenons un meilleur pouvoir prédictif par le modèle, notamment liée à la forte corrélation entre le ratio interdécile et la variable à expliquer  \")\n",
    "print(\" ----- INTERPRETATION : nous regarderons ultérieurement les résidus  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3cd5bc-a9b5-45ac-8923-629e0a08be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*100)\n",
    "print(\" \"*100)\n",
    "print(\"Une régression multiple sur l'ensemble des données non transformées part statsmodel :\")\n",
    "print(\" Crim_Del_PN_GN_hab ~  Nb_Boucherie_dep_hab + MED18 + TP6018 + D118 + D918 + RD18  + T1_2018+    Nb_PN_GN_dep_100k_hab\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "formula_reg= \" Crim_Del_PN_GN_hab ~  Nb_Boucherie_dep_hab + MED18 + TP6018 + D118 + D918 + RD18  + T1_2018+    Nb_PN_GN_dep_100k_hab\"\n",
    "reg_with_statsmodels = ols( formula_reg, data = donnees_2018_hab).fit()\n",
    "print(reg_with_statsmodels.summary())\n",
    "\n",
    "\n",
    "print(\" \"*100)\n",
    "print(\" ----- INTERPRETATION : on obtient de nouveau le même R² et les mêmes coefficients  \")\n",
    "print(\" ----- INTERPRETATION : Toutes les coefficients sont significatifs sauf Nb_Boucherie_dep_hab et Nb_PN_GN_dep_100k_hab \")\n",
    "print(\" ----- INTERPRETATION : On peut déjà esquisser l'hypothèse qu'il sera difficile de montrer un usage du nombre de boucherie sur le nombre des crimes\")\n",
    "print(\" ----- INTERPRETATION : La note [2] nous suggère un problème de multicollinéarité (potentiellement résoluble par une régression PLS)  ou un problème avec les variables numériques\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb97ec-58bb-44ed-bde9-7f8039f3924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*100)\n",
    "print(\" \"*100)\n",
    "print(\"Retour sur les résidus :\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "sns.residplot(predictions.reshape(-1),'Crim_Del_PN_GN_hab', data=donnees_2018_hab,lowess=True,\n",
    "                                  line_kws={'color': 'red', 'lw': 1, 'alpha': 1})\n",
    "plt.xlabel(\"Fitted values\")\n",
    "plt.title('Residual plot')\n",
    "\n",
    "print(\" ----- INTERPRETATION : pour deux départements quasi-similaires en termes socio-économiques, on peut constater un important écart de prédiction de 4000 crimes et délits  \")\n",
    "print(\" ----- INTERPRETATION : l'amplitude d'un résidu est de +/-2000 crimes et délits, sachant que la médiane parmi les départements est aux alentours de 4000 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c17af4b-5e88-406e-a0f4-d86fd7ad663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = donnees_2018_hab[\"Crim_Del_PN_GN_hab\"] - predictions.reshape(-1)\n",
    "residuals\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q Plot\")\n",
    "\n",
    "print(\" ----- INTERPRETATION : La normalité des résidus peut être conjecturée si l'on ne considère pas les points atypiques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4da845-c6be-4b5b-929a-b73c42a5ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_norm_residuals_abs_sqrt=np.sqrt(np.abs(residuals))\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.regplot(predictions.reshape(-1), model_norm_residuals_abs_sqrt,\n",
    "              scatter=True,\n",
    "              lowess=True,\n",
    "              line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "plt.ylabel(\"Standarized residuals\")\n",
    "plt.xlabel(\"Fitted value\")\n",
    "\n",
    "\n",
    "print(\" ----- INTERPRETATION : L'hypothèse d'homoscédasticité ne peut être faite ici.\")\n",
    "print(\" ----- INTERPRETATION : En présence d'hétéroscédasticité, l'ouvrage du Woolridge nous suggère d'utiliser le log (ou log(1+y)) pour : \")\n",
    "print(\" ----- INTERPRETATION : * les variables de population \")\n",
    "print(\" ----- INTERPRETATION : * les variables monétaires \")\n",
    "print(\" ----- INTERPRETATION : * les pourcentages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bfead7-868c-4435-b011-1bb9d7a8fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*100)\n",
    "print(\" \"*100)\n",
    "print(\"Une régression multiple en cross validation avec des données non transformées\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "scores = cross_val_score(lm, X, Y, scoring='r2', cv=5)\n",
    "print(\"R² obtenu en cross validation\",scores)\n",
    "\n",
    "print(\" \"*100)\n",
    "print(\" ----- INTERPRETATION : En utilisant la validation croisée, nous obtenons plusieurs R² très différents, de quasi-nulle à 0.72\")\n",
    "print(\" ----- INTERPRETATION : La forte variabilité du R², compte tenu du faible nombre d'invidividus dans l'échantillon, montre la sensibilité aux outliers\")\n",
    "print(\" ----- INTERPRETATION : Ceci présage également la présence de différents groupes hétérogènes comme dans le clustering dans le chapitre 2\")\n",
    "# R² can be negative with small datasets and cv fold https://stackoverflow.com/questions/23036866/scikit-learn-is-returning-coefficient-of-determination-r2-values-less-than-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1741be6f-a664-4bed-90ba-42e5cbaa4b36",
   "metadata": {},
   "source": [
    "## 1-C Régression linéaire multiple avec transformation log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4490a9-0e15-48e1-81fc-cbae3c86f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*100)\n",
    "print(\" \"*100)\n",
    "print(\"Une régression multiple sur l'ensemble des données log-transformées\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "new_donnees_2018_hab=donnees_2018_hab.copy()\n",
    "new_donnees_2018_hab['Crim_Del_PN_GN_hab'] = np.log(new_donnees_2018_hab['Crim_Del_PN_GN_hab'])\n",
    "new_donnees_2018_hab['RD18'] = np.log(new_donnees_2018_hab['RD18'])\n",
    "new_donnees_2018_hab['D918'] = np.log(new_donnees_2018_hab['D918'])\n",
    "new_donnees_2018_hab['D118'] = np.log(new_donnees_2018_hab['D118'])\n",
    "new_donnees_2018_hab['TP6018'] = np.log(new_donnees_2018_hab['TP6018'])\n",
    "new_donnees_2018_hab['MED18'] = np.log(new_donnees_2018_hab['MED18'])\n",
    "new_donnees_2018_hab['Nb_Boucherie_dep_hab'] = np.log(new_donnees_2018_hab['Nb_Boucherie_dep_hab'])\n",
    "new_donnees_2018_hab['Nb_PN_GN_dep_100k_hab'] = np.log(new_donnees_2018_hab['Nb_PN_GN_dep_100k_hab'])\n",
    "new_donnees_2018_hab['T1_2018'] = np.log(new_donnees_2018_hab['T1_2018'])\n",
    "\n",
    "\n",
    "formula_reg= \" Crim_Del_PN_GN_hab ~  Nb_Boucherie_dep_hab + MED18 + TP6018 + D118 + D918 + RD18  + T1_2018+    Nb_PN_GN_dep_100k_hab\"\n",
    "#formula_reg= \" Crim_Del_PN_GN_hab ~  Nb_Boucherie_dep_hab + MED18 + TP6018   + T1_2018 +    Nb_PN_GN_dep_100k_hab\"\n",
    "\n",
    "reg_with_statsmodels = ols( formula_reg, data = new_donnees_2018_hab).fit()\n",
    "print(reg_with_statsmodels.summary())\n",
    "\n",
    "\n",
    "print(\" \"*100)\n",
    "print(\" ----- INTERPRETATION : En passant au log, nous avons perdu en pouvoir prédictif R²=0.678\")\n",
    "print(\" ----- INTERPRETATION : Beaucoup de coefficients ne sont plus significatifs à 5% par rapport à la modélisation précédente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192c5ea-0e8a-4afe-ae8b-cf59c21a85d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formula_reg= \" Crim_Del_PN_GN_hab ~  Nb_Boucherie_dep_hab    + TP6018 + D118 + D918 + RD18 +Nb_PN_GN_dep_100k_hab\"\n",
    "# reg_with_statsmodels = ols( formula_reg, data = new_donnees_2018_hab).fit()\n",
    "# print(reg_with_statsmodels.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13751e33-f873-42b3-b728-66b5a219f067",
   "metadata": {},
   "source": [
    "## 1-D Régression linéaire multiple avec transformation log et sans les outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651af4f3-bb40-434f-b5de-461fc6434dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*100)\n",
    "print(\" \"*100)\n",
    "print(\"Une régression multiple sur l'ensemble des données log-transformées sans les outliers pour la variable Crim_Del_PN_GN_hab\")\n",
    "print(\"-\"*100)\n",
    "new_donnees_2018_hab=donnees_2018_hab[donnees_2018_hab['Crim_Del_PN_GN_hab']<6700].copy()\n",
    "new_donnees_2018_hab['Crim_Del_PN_GN_hab'] = np.log(new_donnees_2018_hab['Crim_Del_PN_GN_hab'])\n",
    "new_donnees_2018_hab['RD18'] = np.log(new_donnees_2018_hab['RD18'])\n",
    "new_donnees_2018_hab['D918'] = np.log(new_donnees_2018_hab['D918'])\n",
    "new_donnees_2018_hab['D118'] = np.log(new_donnees_2018_hab['D118'])\n",
    "new_donnees_2018_hab['TP6018'] = np.log(new_donnees_2018_hab['TP6018'])\n",
    "new_donnees_2018_hab['MED18'] = np.log(new_donnees_2018_hab['MED18'])\n",
    "new_donnees_2018_hab['Nb_Boucherie_dep_hab'] = np.log(new_donnees_2018_hab['Nb_Boucherie_dep_hab'])\n",
    "new_donnees_2018_hab['Nb_PN_GN_dep_100k_hab'] = np.log(new_donnees_2018_hab['Nb_PN_GN_dep_100k_hab'])\n",
    "new_donnees_2018_hab['T1_2018'] = np.log(new_donnees_2018_hab['T1_2018'])\n",
    "\n",
    "formula_reg= \" Crim_Del_PN_GN_hab ~  Nb_Boucherie_dep_hab + MED18 + TP6018 + D118 + D918 + RD18  + T1_2018+    Nb_PN_GN_dep_100k_hab\"\n",
    "\n",
    "# formula_reg= \" Crim_Del_PN_GN_hab ~  Nb_Boucherie_dep_hab + MED18 + TP6018   + T1_2018 +    Nb_PN_GN_dep_100k_hab\"\n",
    "#formula_reg= \" Crim_Del_PN_GN_hab ~  Nb_Boucherie_dep_hab + Nb_PN_GN_dep_100k_hab  +T1_2018 + TP6018    \"\n",
    "reg_with_statsmodels = ols( formula_reg, data = new_donnees_2018_hab).fit()\n",
    "print(reg_with_statsmodels.summary())\n",
    "\n",
    "\n",
    "print(\" \"*100)\n",
    "print(\" ----- INTERPRETATION : En passant au log et sans les outliers, nous avons perdu en pouvoir prédictif R²=0.592\")\n",
    "print(\" ----- INTERPRETATION : Beaucoup de coefficients ne sont plus significatifs à 5% par rapport à la modélisation précédente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce20ef9-172e-40b2-9a63-886923e330c2",
   "metadata": {},
   "source": [
    "## 1-E Régression linéaire multiple avec clusterisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6bb006-6b34-45fa-9d24-6935867402c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees_2018_hab_clusterisees=donnees_2018_hab.merge(X_cluster,how=\"inner\",left_index=True,right_index=True)\n",
    "donnees_2018_hab_clusterisees=pd.get_dummies(donnees_2018_hab_clusterisees, columns=['Cluster'])\n",
    "\n",
    "formula_reg= \" Crim_Del_PN_GN_hab ~  Nb_Boucherie_dep_hab + MED18 + TP6018 + D118 + D918 + RD18  + T1_2018+    Nb_PN_GN_dep_100k_hab + Cluster_0 + Cluster_1\"\n",
    "reg_with_statsmodels = ols( formula_reg, data = donnees_2018_hab_clusterisees).fit()\n",
    "print(reg_with_statsmodels.summary())\n",
    "\n",
    "\n",
    "print(\" \"*100)\n",
    "print(\" ----- INTERPRETATION : En clusterisant, nous obtenons un meilleur pouvoir prédictif R²=0.788\")\n",
    "print(\" ----- INTERPRETATION : Le coefficient du nombre de boucherie n'est pas toujours pas significatif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4451e4eb-a2f4-4efb-9446-3c262942e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees_2018_hab_clusterisees_log=donnees_2018_hab_clusterisees.copy()\n",
    "donnees_2018_hab_clusterisees_log['Crim_Del_PN_GN_hab'] = np.log(donnees_2018_hab_clusterisees_log['Crim_Del_PN_GN_hab'])\n",
    "donnees_2018_hab_clusterisees_log['RD18'] = np.log(donnees_2018_hab_clusterisees_log['RD18'])\n",
    "donnees_2018_hab_clusterisees_log['D918'] = np.log(donnees_2018_hab_clusterisees_log['D918'])\n",
    "donnees_2018_hab_clusterisees_log['D118'] = np.log(donnees_2018_hab_clusterisees_log['D118'])\n",
    "donnees_2018_hab_clusterisees_log['TP6018'] = np.log(donnees_2018_hab_clusterisees_log['TP6018'])\n",
    "donnees_2018_hab_clusterisees_log['MED18'] = np.log(donnees_2018_hab_clusterisees_log['MED18'])\n",
    "donnees_2018_hab_clusterisees_log['Nb_Boucherie_dep_hab'] = np.log(donnees_2018_hab_clusterisees_log['Nb_Boucherie_dep_hab'])\n",
    "donnees_2018_hab_clusterisees_log['Nb_PN_GN_dep_100k_hab'] = np.log(donnees_2018_hab_clusterisees_log['Nb_PN_GN_dep_100k_hab'])\n",
    "donnees_2018_hab_clusterisees_log['T1_2018'] = np.log(donnees_2018_hab_clusterisees_log['T1_2018'])\n",
    "\n",
    "formula_reg= \" Crim_Del_PN_GN_hab ~  Nb_Boucherie_dep_hab + MED18 + TP6018 + D118 + D918 + RD18  + T1_2018+    Nb_PN_GN_dep_100k_hab + Cluster_0 + Cluster_1\"\n",
    "reg_with_statsmodels = ols( formula_reg, data = donnees_2018_hab_clusterisees_log).fit()\n",
    "print(reg_with_statsmodels.summary())\n",
    "\n",
    "print(\" \"*100)\n",
    "print(\" ----- INTERPRETATION : Le passage au log pour les variables hors dummies n'améliore pas le modèle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffbd5e4-8370-48e3-b904-1ad09b793ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees_2018_hab_cluster_0=donnees_2018_hab_clusterisees[donnees_2018_hab_clusterisees.Cluster_0==1]\n",
    "donnees_2018_hab_cluster_1=donnees_2018_hab_clusterisees[donnees_2018_hab_clusterisees.Cluster_1==1]\n",
    "donnees_2018_hab_cluster_2=donnees_2018_hab_clusterisees[donnees_2018_hab_clusterisees.Cluster_2==1]\n",
    "\n",
    "\n",
    "formula_reg= \" Crim_Del_PN_GN_hab ~  Nb_Boucherie_dep_hab + MED18 + TP6018 + D118 + D918 + RD18  + T1_2018+    Nb_PN_GN_dep_100k_hab\"\n",
    "\n",
    "\n",
    "# le numero peut changer entre deux exécutions différentes\n",
    "if not \"75\" in donnees_2018_hab_cluster_0.index:\n",
    "    reg_with_statsmodels = ols( formula_reg, data = donnees_2018_hab_cluster_0).fit()\n",
    "    print(reg_with_statsmodels.summary())\n",
    "\n",
    "    \n",
    "if not \"75\" in donnees_2018_hab_cluster_1.index:    \n",
    "    reg_with_statsmodels = ols( formula_reg, data = donnees_2018_hab_cluster_1).fit()\n",
    "    print(reg_with_statsmodels.summary())\n",
    "\n",
    "if not \"75\" in donnees_2018_hab_cluster_2.index:\n",
    "    reg_with_statsmodels = ols( formula_reg, data = donnees_2018_hab_cluster_2).fit()\n",
    "    print(reg_with_statsmodels.summary())\n",
    "\n",
    "\n",
    "print(\" \"*100)\n",
    "print(\" ----- INTERPRETATION : une régression différente par cluster permet d'affiner l'analyse et la prédictibilité des modèles\")\n",
    "print(\" ----- INTERPRETATION : Impossible de faire une regression sur le dernier cluster car il y a un unique point : Paris\")\n",
    "# reg_with_statsmodels = ols( formula_reg, data = donnees_2018_hab_cluster_2).fit()\n",
    "# print(reg_with_statsmodels.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee5998-4229-43c8-a373-d0b619d79ee6",
   "metadata": {},
   "source": [
    "# 2 - Approche Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed411332-ba36-4f45-85a5-e31cd78664de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html\n",
    "# Both StandardScaler and MinMaxScaler are very sensitive to the presence of outliers.\n",
    "# MaxAbsScaler therefore also suffers from the presence of large outliers.\n",
    "\n",
    "display(Image(\"https://scikit-learn.org/stable/_static/ml_map.png\"))\n",
    "print(\" ----- ML : nous disposons d'une échantillon de taille >50 et <100K où le nombre de variables explicatives est faible, nous nous orientons vers une régression LASSO pour prédire le nombre de crimes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4e57b-a050-45bf-b4e6-f6986bfd0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\" ----- ML : avec l'algorithme LASSO, plus le coefficient est grand et plus il va couter dans le modèle. Le modèle choisira à moindre coût les meilleurs variables prédictives\")\n",
    "\n",
    "for i in range(10):\n",
    "    print(\" !!!!! Simulation {}\".format(i))\n",
    "    df_train, df_test = train_test_split(donnees_2018_hab, \n",
    "                                         train_size = 0.7, \n",
    "                                         test_size = 0.3\n",
    "                                        )\n",
    "\n",
    "    X_train=df_train[['MED18', 'TP6018', 'D118', 'D918', 'RD18', 'T1_2018',\n",
    "           'Nb_PN_GN_dep_100k_hab', 'Nb_Boucherie_dep_hab']].values.reshape(-1,8)\n",
    "    y_train=df_train['Crim_Del_PN_GN_hab'].values.reshape(-1,1)\n",
    "\n",
    "    X_test=df_test[['MED18', 'TP6018', 'D118', 'D918', 'RD18', 'T1_2018',\n",
    "           'Nb_PN_GN_dep_100k_hab', 'Nb_Boucherie_dep_hab']].values.reshape(-1,8)\n",
    "    y_test=df_test['Crim_Del_PN_GN_hab'].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "    pipeline= Pipeline(\n",
    "        [('scaler',RobustScaler()),\n",
    "         ('model',Lasso())\n",
    "        ])\n",
    "\n",
    "\n",
    "    search=GridSearchCV(pipeline,\n",
    "                        {'model__alpha':np.arange(0.1,4,0.1),\n",
    "                        },\n",
    "                        cv=5,\n",
    "                        scoring='r2',\n",
    "                        verbose=0\n",
    "                       )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    display(search.best_params_)\n",
    "    print(['MED18', 'TP6018', 'D118', 'D918', 'RD18', 'T1_2018',\n",
    "           'Nb_PN_GN_dep_100k_hab', 'Nb_Boucherie_dep_hab'])\n",
    "    print(\"Coefficients : \", search.best_estimator_[1].coef_)\n",
    "    Y_pred=search.predict(X_test)\n",
    "    print(\"Données prédites :\",Y_pred)\n",
    "    print(\"Données observées :\",y_test)\n",
    "\n",
    "    print(\"R² sur les données d'entrainement :\",search.score(X_train, y_train))\n",
    "    print(\"R² sur les données de test :\",search.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
